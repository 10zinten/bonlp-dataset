{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from pathlib import Path\n",
    "import yaml as yml\n",
    "import jsonpickle as jp    \n",
    "\n",
    "from pybo import BoPipeline                                                                                           \n",
    "from lighttag.prepare_datasets import paragraphify, sentencify\n",
    "\n",
    "jp.set_encoder_options('simplejson', sort_keys=True, indent=4, ensure_ascii=False)                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def parse_keys(path):\n",
    "    text = path.read_text()\n",
    "    keys = yml.load(text)\n",
    "    return keys\n",
    "\n",
    "\n",
    "def filter_and_format_para(paras):\n",
    "    output = []\n",
    "    keys_path = Path('data/keys/test_keys.yml').resolve()\n",
    "    keys = parse_keys(keys_path)\n",
    "    for i, para in enumerate(paras):                                                                              \n",
    "        para_str = ''.join([token.content for token in para[1]])\n",
    "        for key in keys:\n",
    "            if key in para_str:                                \n",
    "                output.append({'ex': para_str, 'order': i})\n",
    "                break\n",
    "                                                                                                                      \n",
    "    return jp.dumps(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_para = [\"ལྷ་དག་གཟུགས་ཀྱི་མཚན་ཉིད་ནི་གཟུགས་སུ་རུང་བ་སྟེ།\", \"དེ་ལ་གཟུགས་སུ་རུང་བའི་མཚན་ཉིད་ཅན་ནི་གཟུགས་སོ།\"]\n",
    "\n",
    "# filter_and_format_para(test_para, keys_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "pipeline = BoPipeline('dummy',                            # preprocessor                                                         \n",
    "                      'pybo',                             # tokenizer\n",
    "                      ('pybo_paragraphs', paragraphify),  # processor                                                           \n",
    "                      filter_and_format_para,             # formatter                                                        \n",
    "                      pybo_profile='GMD')                 # pybo_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.pipe_file('data/test_corpus.txt', 'data/toupload')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### export the notebook to script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted create_dataset.ipynb to create_dataset.py\r\n"
     ]
    }
   ],
   "source": [
    "!python ../utils/notebook2script.py create_dataset.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
